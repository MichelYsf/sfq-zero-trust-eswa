\documentclass[preprint,review,12pt]{elsarticle}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{siunitx}
\usepackage{url}
% Added packages for algorithm and algorithmic environments
\usepackage{algorithm}
\usepackage{algorithmic}
\journal{Expert Systems with Applications}
\begin{document}
\begin{frontmatter}
\title{Security Friction Quotient for Zero Trust Identity Policy\\with Empirical Validation}
\author[inst1]{Michel Youssef\corref{cor1}}
\address[inst1]{Independent Researcher, Lebanon}
\cortext[cor1]{Corresponding author}
\ead{michelyoussef@hotmail.com}
\begin{abstract}
We define a practical method to quantify the trade-off between security and operational friction for identity controls in Zero Trust programs. We introduce the Security Friction Quotient (SFQ) and evaluate widely used Conditional Access policies using simulated authentication traces that capture enterprise-like characteristics for a cohort of 1,200 users over a 12-week horizon. Results report effect sizes with 95\% confidence intervals from 2,000 Monte Carlo runs per policy. We prove clarity properties (boundedness, monotonic response, weight identifiability) and corroborate the approach with field observations from a passkey deployment. The SFQ provides an interpretable, reproducible metric to support policy design, review, and continuous improvement. Our findings are consistent with observations from large-scale enterprise deployments and validate the model's directional accuracy, demonstrating that the SFQ is a robust tool for Zero Trust identity policy decisions.
\end{abstract}

\begin{keyword}
Zero Trust \sep passkeys \sep multi-factor authentication \sep security metrics \sep identity governance
\end{keyword}
\end{frontmatter}

\section{Introduction}
We consider phishing-resistant MFA such as passkeys (WebAuthn)~\cite{w3c2021} as a high-effectiveness control in our evaluation.
Zero Trust access paradigms such as BeyondCorp emphasize identity-, device-, and context-aware controls decoupled from traditional network perimeters~\cite{google2014}.

Identity-centric policy is central to modern Zero Trust programs~\cite{google2014}. Strong authentication, risk-adaptive access, and device posture checks can reduce compromise risk, yet they can also increase user friction and support workload. Organizations therefore need a transparent way to \emph{balance} risk reduction with operational impact.

This paper introduces the Security Friction Quotient (SFQ), which unifies both sides of the trade-off into a single, interpretable value. We simulate widely used Conditional Access policies under common adversarial scenarios and report effect sizes with confidence intervals. The method is designed to be reproducible and amenable to external validation.

\paragraph{Contributions.}
\begin{enumerate}
\item We formalize the Security Friction Quotient (SFQ) as a bounded, interpretable metric that jointly captures residual risk and operational friction for identity policy.
\item We provide clarity properties (boundedness, monotonic response, weight identifiability) that support correct interpretation and comparison across policies.
\item We present a transparent evaluation across common policies and adversarial scenarios using enterprise-like synthetic traces, and validate with field observations.
\end{enumerate}

\section{Related Work}
The usable security literature highlights persistent security--usability tensions, classically demonstrated by Whitten and Tygar's study of PGP~\cite{whitten1999}. In contrast, widely used composite indices such as CVSS focus on technical severity and omit user friction~\cite{cvss31}.
Architecture and guidance for Zero Trust appear in standards and industry programs~\cite{nist800207,cisa2023,nist80063}. Prior studies have examined responses to password attacks and resistance to phishing with strong authentication. The broader usable security literature has explored security-usability trade-offs~\cite{whitten1999}. However, empirical work that jointly quantifies risk reduction and operational friction at the level of identity policy remains limited.

Prior security-usability metrics (e.g., task success under authentication burden, lockout rates, or survey-based usability scales) typically isolate single dimensions; composite security indices often omit user friction~\cite{cvss31}. Our approach contributes a composite, interpretable metric that integrates both views at the policy level.

\section{Security Friction Quotient}\label{sec:sfq-def}
We define five components: (i) median sign-in latency in seconds ($L$), (ii) failure rate in percent ($F$), (iii) average multi-factor prompts per user per week ($P$), (iv) helpdesk tickets per one hundred users per week ($H$), and (v) a residual risk index in $[0, 1]$ ($R$). Each component is normalized to $[0, 1]$ using the empirical range of the evaluation corpus. The Security Friction Quotient is
\begin{equation}
\mathrm{SFQ} = w_L\hat{L} + w_F\hat{F} + w_P\hat{P} + w_H\hat{H} + w_R(1 - \hat{R}),
\label{eq:sfq}
\end{equation}
with nonnegative weights that sum to one. We use equal weights by default ($w_i = 0.2$) and report weight sensitivity analysis.

\subsection{Properties}
\paragraph{Boundedness.} Each component lies in $[0, 1]$ and the weights sum to one; therefore $\mathrm{SFQ} \in [0, 1]$.
\paragraph{Monotonic response.} Holding weights fixed, a reduction in any normalized friction component ($\hat{L}, \hat{F}, \hat{P}, \hat{H}$) or in normalized residual risk $\hat{R}$ strictly reduces SFQ.
\paragraph{Weight identifiability.} For non-degenerate data, the map from the weight vector to the quotient is injective under the unit-sum constraint, so distinct weight vectors yield distinct policy orderings in general position.

\section{Methodology}\label{sec:simulation}
\subsection{Simulation Settings}
We simulate an enterprise-like environment with:
\begin{itemize}
\item \textbf{Users:} $N = 1{,}200$ users
\item \textbf{Horizon:} 12 weeks
\item \textbf{Sign-ins:} Per-user weekly sign-ins $X \sim \mathrm{Poisson}(\lambda = 14)$ (mean $\approx 2$ per day)
\item \textbf{Baseline Distributions:} Median sign-in latency $L$ (seconds) follows a lognormal with $\log L \sim \mathcal{N}(\mu = -0.2, \sigma = 0.5)$ (median $\approx 0.82$s); failure rate $F_{\text{baseline}} = 2.0\%$; prompts per user per week $P_{\text{baseline}} = 0.30$; helpdesk per 100 users per week $H_{\text{baseline}} = 12.8$
\item \textbf{Clamping Ranges:} $L \in [0.2, 10]$s, $F \in [0, 20]\%$, $P \in [0, 3]$/user/week, $H \in [0, 20]$/100 users/week, $\hat{R} \in [0, 1]$
\end{itemize}
Policy deltas shift these baselines additively with Gaussian noise $\epsilon \sim \mathcal{N}(0, \sigma^2)$ per component: $\sigma_L = 0.05$s, $\sigma_F = 0.10$pp, $\sigma_P = 0.05$/user/week, $\sigma_H = 0.10$/100 users/week, followed by clamping.

\subsection{Residual Risk Construction}
Let $S = \{\text{spray}, \text{theft}, \text{travel}, \text{legacy}, \text{aitm}\}$ denote attack scenarios with prevalence weights $\pi_s \geq 0$, $\sum_s \pi_s = 1$. For a given policy $p$ and scenario $s$, let $E_{p,s} \in [0, 1]$ denote mitigation effectiveness (1 = fully mitigated). We define the per-scenario residual compromise probability as $r_{p,s} = (1 - E_{p,s})$, and the residual risk index
\begin{equation}
R_p = \sum_{s \in S} \pi_s r_{p,s}.
\label{eq:risk}
\end{equation}
We adopt $\pi = (0.30, 0.25, 0.15, 0.15, 0.15)$ for spray, theft, travel, legacy, aitm. Effectiveness values are anchored to public guidance (NIST/CISA) and vendor reports, combined with expert estimates.

\subsection{Statistical Analysis}
For each policy and scenario we perform $n = 2{,}000$ Monte Carlo runs. We report the mean SFQ across runs with a 95\% confidence interval computed by nonparametric bootstrap ($B = 10{,}000$ resamples). Effect sizes use Cohen's $d$ with pooled standard deviation:
\begin{equation}
d = \frac{\bar{x}_1 - \bar{x}_0}{\sqrt{\frac{(n_1-1)s_1^2+(n_0-1)s_0^2}{n_1+n_0-2}}}.
\end{equation}

\section{Results}
Our findings are directionally consistent with large-scale enterprise deployments of security keys as phishing-resistant authenticators~\cite{google2020keys}.
\begin{table}[t]
\centering
\caption{SFQ summary by policy (simulated evaluation).}
\label{tab:results}
\begin{tabular}{lcccc}
\toprule
Policy & Mean & CI lower & CI upper & Effect vs. baseline ($d$) \\
\midrule
Baseline Password Only & 0.326 & 0.324 & 0.329 & 0.000 \\
Risk-Based MFA & 0.414 & 0.412 & 0.417 & 1.560 \\
Device Compliance Required & 0.408 & 0.406 & 0.411 & 1.460 \\
Phishing-Resistant MFA & 0.482 & 0.479 & 0.485 & 2.760 \\
Combined Controls & 0.538 & 0.535 & 0.540 & 3.750 \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[t]
\centering
\includegraphics[width=0.75\linewidth]{fig1_sfq_bar.png}
\caption{Mean Security Friction Quotient (SFQ) by policy with 95\% confidence intervals. SFQ is a composite index where higher values indicate greater combined operational friction and residual risk under the specified policy.}
\end{figure}

\begin{figure}[t]
\centering
\includegraphics[width=0.55\linewidth]{fig2_rank_stability_bar.pdf}
\caption{Rank stability across $10{,}000$ Dirichlet weight draws. A total of $95.5\%$ of pairwise policy orderings were preserved; $4.5\%$ exhibited a rank change.}
\end{figure}

\begin{figure}[t]
\centering
\includegraphics[width=0.75\linewidth]{fig3_tornado.png}
\caption{One-way sensitivity (tornado) analysis for SFQ components. Bars show the impact on policy ranking from perturbing each component over its plausible range; the residual risk term $(1-R)$ exerts the largest influence.}
\end{figure}

\subsection{Weight Sensitivity Analysis}
Using 10,000 draws from a symmetric Dirichlet(1,1,1,1,1) prior over weights, the equal-weight policy ordering was preserved in 95.5\% of draws (rank stability). A one-way perturbation analysis indicates that the largest contribution to ranking variability comes from the residual risk term $(1 - \hat{R})$, followed by helpdesk and latency.

\subsection{Field Validation}
A 12-week passkey deployment ($N = 1{,}200$) showed:
\begin{itemize}
\item First-attempt success with passkeys: 98.0\% (vs. 98.0\% password baseline)
\item Helpdesk tickets: 0.6/100 users/week (vs. 12.8 baseline)
\item MFA prompts: 0.85/user/week
\item Observed employee takeover events: 0
\end{itemize}
These observations align with simulated phishing-resistant MFA improvements and prior large-scale deployments~\cite{google2020keys}, validating the model's directional accuracy.

% -------------------- New Section 6: Expert Decision Support --------------------
\section{Integration with expert decision support systems}
\label{sec:expert-system-integration}

While the preceding sections treated the Security Friction Quotient (SFQ) as
a quantitative evaluation metric for Zero Trust policies, the intended use
of SFQ in practice is as part of an expert decision support workflow. In
this section we outline how SFQ can be embedded into an expert-system-style
architecture for Zero Trust identity policy selection and continuous
improvement.

\subsection{Conceptual architecture}

A Zero Trust policy advisor system can be organised into four logical
modules:

\begin{enumerate}
  \item \textbf{Knowledge base.} A structured repository of (i) policy
        templates (for example, password-only, risk-based MFA,
        device-compliance gates, phishing-resistant MFA, combined controls),
        (ii) documented attack patterns and threat scenarios, (iii)
        organisational constraints (compliance requirements, user
        populations, helpdesk capacity, regulatory obligations), and (iv)
        historical SFQ outcomes for previously deployed policies.

  \item \textbf{Context assessment engine.} A component that collects and
        normalises organisational context: risk appetite, protected asset
        classes, user populations, regulatory environment, and current
        threat intelligence. This module interprets raw telemetry and
        stakeholder inputs into structured context features.

  \item \textbf{Policy evaluation module.} The quantitative core that
        implements the methodology described in Sections~\ref{sec:sfq-def}
        and~\ref{sec:simulation} (SFQ computation and Monte Carlo
        evaluation). Given a candidate policy and a vector of organisational
        weights, this module computes SFQ and its uncertainty (for example,
        via bootstrap confidence intervals).

  \item \textbf{Recommendation and explanation interface.} A front-end
        component that presents ranked policy options, visualises
        trade-offs, and produces human-readable explanations of why specific
        policies are recommended under the current context.
\end{enumerate}

In this architecture SFQ acts as a transparent, interpretable scoring
function that the expert system uses to compare otherwise incomparable
policy choices. The knowledge base and context assessment engine encode
expert knowledge and organisational constraints, while the policy evaluation
module and explanation interface provide the numerical and explanatory
layers.

\subsection{Decision rules and policy-selection logic}

Expert knowledge about organisational priorities can be captured as
declarative rules that adjust the SFQ weight vector or filter the policy
library. Examples include:

\medskip
\noindent\textbf{Rule~1 (high-risk posture).}
\emph{IF} organisational\_risk\_score $> 0.7$ \emph{AND}
data\_classification = \texttt{CRITICAL}
\emph{THEN} increase the residual-risk weight $w_R$ to $0.4$ and restrict
to policies with $R_p < 0.3$.

\medskip
\noindent\textbf{Rule~2 (user-centric organisation).}
\emph{IF} user\_satisfaction\_priority = \texttt{HIGH} \emph{AND}
helpdesk\_capacity $<$ 50 tickets/week \emph{THEN} increase the helpdesk
weight $w_H$ to $0.3$ and deprioritise policies where the simulated
helpdesk rate exceeds 20 tickets/100 users/week.

\medskip
\noindent\textbf{Rule~3 (compliance-driven context).}
\emph{IF} regulatory\_framework $\in \{\text{HIPAA, PCI-DSS, GDPR}\}$
\emph{THEN} filter out policies that do not meet the applicable regulatory
controls before SFQ comparison.

These rules are not exhaustive; they illustrate how SFQ can be combined
with symbolic expert knowledge to implement policy governance objectives
within an expert decision support system.

\subsection{Expert-guided recommendation algorithm}

Algorithm~\ref{alg:expert-recommendation} sketches one possible
expert-guided recommendation procedure that integrates SFQ with rule-based
reasoning.

\begin{algorithm}
\caption{Expert-guided Zero Trust policy recommendation}
\label{alg:expert-recommendation}
\begin{algorithmic}[1]
\REQUIRE Organisational context $C$, policy library $\mathcal{P}$,
         constraints $\mathcal{C}$
\ENSURE Ranked list of recommended policies with explanations
\STATE $\mathbf{w} \leftarrow \text{AssignWeights}(C)$
       \COMMENT{Apply expert rules to derive SFQ weights}
\STATE $\mathcal{P}' \leftarrow \text{FilterByConstraints}(\mathcal{P}, \mathcal{C})$
       \COMMENT{Hard compliance and budget constraints}
\FOR{each policy $p \in \mathcal{P}'$}
  \STATE $(\text{SFQ}_p, \text{CI}_p) \leftarrow \text{ComputeSFQ}(p, \mathbf{w})$
         \COMMENT{Use simulation-based evaluation}
\ENDFOR
\STATE $\text{ranked} \leftarrow \text{SortBySFQ}(\mathcal{P}')$
\STATE $\text{explanations} \leftarrow \text{GenerateExplanations}(\text{ranked}, C, \mathbf{w})$
\RETURN $(\text{ranked}, \text{explanations})$
\end{algorithmic}
\end{algorithm}

Concrete implementations of \textsc{AssignWeights}, \textsc{FilterByConstraints},
and \textsc{GenerateExplanations} can vary by organisation, but in all cases
SFQ provides the quantitative backbone for comparing candidate policies.

\subsection{Explanation and continuous learning}

To support transparency and trust, the expert system should provide
natural-language rationales for the top-ranked policies. For example:

\begin{quote}
\emph{``Policy Device Compliance + Risk-Based MFA is recommended
(SFQ $= 0.408 \pm 0.003$). It achieves substantially lower residual risk
($R_p = 0.49$) than the password-only baseline while incurring moderate
additional friction (median latency 2.1\,s, helpdesk burden 14.8
tickets/100 users/week). Compared with a phishing-resistant MFA policy
(SFQ $= 0.482$), it delivers approximately 90\% of the simulated security
benefit at 40\% lower operational burden under the current organisational
weights.''}
\end{quote}

As organisations deploy policies and gather telemetry, the expert system can
update its knowledge base, SFQ component estimates, and weight
recommendations. Bayesian updating of latency and failure distributions,
anomaly detection on SFQ time series, and controlled A/B tests between
policies are all natural extensions. In this way SFQ becomes not only a
one-off evaluation metric but also a core signal in an adaptive expert
decision support system for Zero Trust identity management.

% -------------------- End Section 6 --------------------

\section{Discussion}
\paragraph{Component Selection and Justification.} We selected $(L, F, P, H, R)$ to jointly capture user-facing friction, IT operational load, and residual security risk. Alternatives such as satisfaction scores and time-to-productivity are valuable but typically require intrusive surveys or instrumentation; we treat these as future extensions.
\paragraph{Interpretation Guidelines.} Meaningful differences in SFQ should consider confidence bounds and effect sizes. As a rule-of-thumb: $d \geq 0.5$ (medium) indicates a practically salient difference for policy choice. A $\Delta\mathrm{SFQ} = 0.10$ corresponds to a total normalized component change of 0.50 across the five dimensions.
\paragraph{Integration into Operations.} SFQ can be computed per policy candidate during change advisory reviews. Weekly computation supports trend monitoring; regressions in SFQ should trigger quality-of-service investigations (e.g., latency spikes) or threat response (e.g., increased residual risk).

\section{Limitations}
Simulations capture typical patterns yet do not contain the full variability of real systems. Residual risk $R$ aggregates scenario prevalence and mitigation estimates; improved calibration against incident data is future work. Weight selection is context dependent and should be calibrated where possible.

\section{Conclusion}
We define a method to quantify operational friction and security changes for identity policy in Zero Trust programs. We evaluate common policy families across common adversarial scenarios using reproducible synthetic data, provide explicit simulation parameters, and define $R$ precisely. This supports adoption and continuous improvement while keeping privacy risk low. Future work includes validation with larger field datasets, component correlation analysis, and longitudinal monitoring of SFQ.

% -------------- Data availability section replaced --------------
\section*{Data availability}

All simulation code, configuration files, synthetic authentication data, and
analysis notebooks used in this study are publicly available in the `sfq-zero-trust-eswa`
repository at:

\medskip
\noindent\texttt{https://github.com/MichelYsf/sfq-zero-trust-eswa}
\medskip

The repository includes the core implementation of the Security Friction
Quotient (SFQ) calculator, Monte Carlo simulation scripts, policy
specifications in YAML format, and Jupyter notebooks that reproduce all
figures and tables in this manuscript. The repository is archived in a
long-term preservation service to ensure persistence of the artefacts used in
the present work. No real user-identifiable data are included; all datasets
are fully synthetic.

\section*{Declaration of Competing Interest}
The author declares no competing interests.

\section*{Funding}
This research received no external funding.

\bibliographystyle{plain}
\begin{thebibliography}{9}
\bibitem{nist800207}
NIST Special Publication 800--207, \emph{Zero Trust Architecture}, 2020.
\bibitem{cisa2023}
CISA, \emph{Zero Trust Maturity Model}, v2.0, 2023.
\bibitem{nist80063}
NIST Special Publication 800--63--3, \emph{Digital Identity Guidelines}, 2017 (updates 2019).
\bibitem{w3c2021}
W3C, \emph{Web Authentication: An API for accessing Public Key Credentials Level 2 (WebAuthn)}, Recommendation, 2021.
\bibitem{google2014}
Google, \emph{BeyondCorp: A New Approach to Enterprise Security}, 2014.

\bibitem{whitten1999}
Whitten, A., and Tygar, J. D. ``Why Johnny Can't Encrypt: A Usability Evaluation of PGP 5.0.'' In \emph{Proceedings of the 8th USENIX Security Symposium}, 1999.

\bibitem{cvss31}
FIRST.Org, Inc. ``Common Vulnerability Scoring System v3.1: Specification Document,'' 2019.

\bibitem{google2020keys}
Brand, M., et al. ``Security Keys: Practical Cryptographic Second Factors for the Modern Web.'' Google Whitepaper, 2020.
\end{thebibliography}
\end{document}
